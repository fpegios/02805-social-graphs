{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "baseUrl = \"https://www.transfermarkt.co.uk\";\n",
    "# Load the webpage containing the data\n",
    "# The very first thing that we are going to do is create a variable called \n",
    "# ‘headers’ and assign it a string that will tell the website that we are a browser, \n",
    "# and not a scraping tool. In short, we’ll be blocked if we are thought to be scraping!\n",
    "headers = {'User-Agent': \n",
    "           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2526.106 Safari/537.36'}\n",
    "\n",
    "page = baseUrl + \"/premier-league/startseite/wettbewerb/GB1\";\n",
    "pageTree = requests.get(page, headers=headers)\n",
    "pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "\n",
    "class Team(object):\n",
    "    \"\"\"__init__() functions as the class constructor\"\"\"\n",
    "    def __init__(self, name=None, smallName=None, link=None, codeName=None, idx=None, city=None):\n",
    "        self.name = name\n",
    "        self.smallName = smallName\n",
    "        self.link = link\n",
    "        self.codeName = codeName\n",
    "        self.idx = idx\n",
    "        self.city = city\n",
    "\n",
    "teams = [];\n",
    "\n",
    "# Locate the data within a page & extract it\n",
    "for teamContainer in pageSoup.find_all('td', {\"class\": \"hauptlink no-border-links hide-for-small hide-for-pad\"}):\n",
    "    name = teamContainer.text; # get team name\n",
    "    link = teamContainer.find('a', {\"class\": \"vereinprofil_tooltip\"}); # get team link, but save full url of team\n",
    "    codeName = link['href'].split('/')[1] # get codeName of each team\n",
    "    idx = link['href'].split('/')[4] # get team index number\n",
    "    \n",
    "    # get team location\n",
    "    pageLocation = baseUrl + \"/\" + codeName + \"/datenfakten/verein/\" + idx;\n",
    "    pageLocationTree = requests.get(pageLocation, headers=headers)\n",
    "    pageLocationSoup = BeautifulSoup(pageLocationTree.content, 'html.parser')\n",
    "\n",
    "    for teamInfo in pageLocationSoup.find_all('table', {\"class\": \"profilheader\"}):\n",
    "        info = teamInfo.find_all('td');\n",
    "        city = info[2].text.split('(')[0][7:]\n",
    "    \n",
    "    teams.append(Team(name, \"\", baseUrl + link['href'], codeName, idx, city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the data within a page & extract it\n",
    "i = 0;\n",
    "for teamSmallNameContainer in pageSoup.find_all('td', {\"class\": \"hauptlink no-border-links show-for-small show-for-pad\"}):\n",
    "    smallName = teamSmallNameContainer.text; # get team's small name\n",
    "    teams[i].smallName = smallName\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix team city manually\n",
    "teams[0].city = \"Manchester\"\n",
    "teams[1].city = \"Liverpool\"\n",
    "teams[2].city = \"London\"\n",
    "teams[3].city = \"London\"\n",
    "teams[4].city = \"Manchester\"\n",
    "teams[5].city = \"London\"\n",
    "teams[6].city = \"Liverpool\"\n",
    "teams[7].city = \"Leicester\"\n",
    "teams[8].city = \"London\"\n",
    "teams[9].city = \"Southampton\"\n",
    "teams[10].city = \"London\"\n",
    "teams[11].city = \"London\"\n",
    "teams[12].city = \"Wolverhampton\"\n",
    "teams[13].city = \"Bournemouth\"\n",
    "teams[14].city = \"Burnley\"\n",
    "teams[15].city = \"Brighton\"\n",
    "teams[16].city = \"Newcastle\"\n",
    "teams[17].city = \"Watford\"\n",
    "teams[18].city = \"Huddersfield\"\n",
    "teams[19].city = \"Cardiff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write team data to file\n",
    "f = open(\"teamData.txt\", \"w\")\n",
    "for team in teams:\n",
    "    line = team.name + \"!\" + team.smallName + \"!\" + team.link + \"!\" + team.codeName + \"!\" + team.idx + \"!\" + team.city + \"\\n\"; # seperate team data with !\n",
    "    line = line.encode('utf-8', 'ignore')\n",
    "    f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get players of all teams\n",
    "class Player(object):\n",
    "    \"\"\"__init__() functions as the class constructor\"\"\"\n",
    "    def __init__(self, name=None, link=None, codeName=None, idx=None, teams=None):\n",
    "        self.name = name\n",
    "        self.link = link\n",
    "        self.codeName = codeName\n",
    "        self.idx = idx\n",
    "        self.teams = teams\n",
    "\n",
    "players = [];\n",
    "\n",
    "for team in teams:\n",
    "    pagePlayers = team.link\n",
    "    pagePlayersTree = requests.get(pagePlayers, headers=headers)\n",
    "    pagePlayersSoup = BeautifulSoup(pagePlayersTree.content, 'html.parser')\n",
    "\n",
    "    i = 1;\n",
    "    for playerInfo in pagePlayersSoup.find_all('a', {\"class\": \"spielprofil_tooltip\"}):\n",
    "        if (i % 2 != 0):\n",
    "            name = playerInfo.text\n",
    "            idx = playerInfo['id']\n",
    "            link = playerInfo['href']\n",
    "            codeName = link.split('/')[1]\n",
    "            players.append(Player(name, baseUrl + link, codeName, idx))\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Manchester City ', u'Liverpool FC ', u'Chelsea FC ', u'Tottenham Hotspur ', u'Manchester United ', u'Arsenal FC ', u'Everton FC ', u'Leicester City ', u'West Ham United ', u'Southampton FC ', u'Fulham FC \\xa0', u'Crystal Palace ', u'Wolverhampton Wanderers \\xa0', u'AFC Bournemouth ', u'Burnley FC ', u'Brighton & Hove Albion ', u'Newcastle United ', u'Watford FC ', u'Huddersfield Town ', u'Cardiff City \\xa0']\n"
     ]
    }
   ],
   "source": [
    "# store team names in an array\n",
    "tNames = []\n",
    "for tName in teams:\n",
    "    tNames.append(tName.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get players past teams\n",
    "for player in players:\n",
    "    pagePlayersTeams = player.link\n",
    "    pagePlayersTeamsTree = requests.get(pagePlayersTeams, headers=headers)\n",
    "    pagePlayersTeamsSoup = BeautifulSoup(pagePlayersTeamsTree.content, 'html.parser')\n",
    "\n",
    "    transferBox = pagePlayersTeamsSoup.find('div', {\"class\": \"box transferhistorie\"})\n",
    "\n",
    "    tempPlayerTeams = [];\n",
    "    # find player teams\n",
    "    for playerTeam in transferBox.find_all('td', {\"class\": \"hauptlink no-border-links hide-for-small vereinsname\"}):\n",
    "        teamName = playerTeam.find('a', {\"class\": \"vereinprofil_tooltip\"})\n",
    "        if teamName:\n",
    "            if teamName.text not in tempPlayerTeams: # avoid duplicate teams\n",
    "                tempPlayerTeams.append(teamName.text)\n",
    "    player.teams = tempPlayerTeams;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write players data to file\n",
    "f = open(\"playersData.txt\", \"w\")\n",
    "for player in players:\n",
    "    line = player.name + \"!\" + player.link + \"!\" + player.codeName + \"!\" + player.idx + \"!\"; # seperate team data with !\n",
    "    i = 1\n",
    "    for playerTeam in player.teams:\n",
    "        if i == len(player.teams):\n",
    "            line = line + playerTeam\n",
    "        else:\n",
    "            line = line + playerTeam + \",\"\n",
    "        i = i + 1\n",
    "    line = line + \"\\n\"\n",
    "    line = line.encode('utf-8', 'ignore')\n",
    "    f.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
